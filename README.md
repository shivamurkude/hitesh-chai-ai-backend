# ğŸš€ Hitesh AI Chat API

> **Namaste! Welcome to Hitesh AI Chat API** - Your tech mentor and chai companion ğŸ«–

A high-performance FastAPI backend that simulates conversations with **Hitesh Choudhary** - India's beloved tech educator, YouTuber, and automation evangelist. This API provides an interactive chat experience with step-by-step processing, streaming responses, and optimized performance.

## ğŸŒŸ Features

### âœ¨ Core Features
- **ğŸ¤– AI-Powered Chat**: Simulates Hitesh Choudhary's personality and teaching style
- **ğŸ”„ Step-by-Step Processing**: Analyze â†’ Think â†’ Output workflow
- **ğŸ“¡ Real-time Streaming**: Server-Sent Events for live response streaming
- **ğŸ’¾ Intelligent Caching**: Redis-based caching for improved performance
- **ğŸ“Š Performance Monitoring**: Built-in metrics and analytics
- **ğŸ”’ Session Management**: Multi-user session support
- **ğŸ¥ Health Checks**: Comprehensive health monitoring

### ğŸ¯ Technical Features
- **âš¡ High Performance**: Optimized with async/await and connection pooling
- **ğŸ›¡ï¸ Security**: CORS, trusted host middleware, and input validation
- **ğŸ“ˆ Scalable**: Docker containerized with Gunicorn workers
- **ğŸ”§ Developer Friendly**: Auto-generated API documentation
- **ğŸŒ Production Ready**: Deployed on Render with environment configuration

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   FastAPI       â”‚    â”‚   OpenAI API    â”‚
â”‚   (React/Vue)   â”‚â—„â”€â”€â–ºâ”‚   Backend       â”‚â—„â”€â”€â–ºâ”‚   GPT-4o-mini   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Redis Cache   â”‚
                       â”‚   (Optional)    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“ Project Structure
```
render-deploy/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI application entry point
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ chat.py            # Pydantic models for data validation
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ chat.py            # API endpoints and routing
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chat_service.py    # Main chat business logic
â”‚   â”‚   â””â”€â”€ hitesh_ai.py       # OpenAI integration and AI processing
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ system_prompt.py   # Hitesh's personality and prompts
â”œâ”€â”€ Dockerfile                 # Container configuration
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ render.yaml               # Render deployment config
â”œâ”€â”€ build.sh                  # Build script
â”œâ”€â”€ start.sh                  # Startup script
â””â”€â”€ README.md                 # This file
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- OpenAI API Key
- Docker (optional)

### 1. Clone the Repository
```bash
git clone <repository-url>
cd render-deploy
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Environment Setup
Create a `.env` file:
```bash
OPENAI_API_KEY=your_openai_api_key_here
DEBUG=false
LOG_LEVEL=info
```

### 4. Run the Application

#### Development Mode
```bash
python -m app.main
```

#### Production Mode (Docker)
```bash
docker build -t hitesh-ai-api .
docker run -p 8000:8000 --env-file .env hitesh-ai-api
```

#### Using Scripts
```bash
chmod +x build.sh start.sh
./build.sh
./start.sh
```

### 5. Access the API
- **API Base URL**: `http://localhost:8000`
- **Interactive Docs**: `http://localhost:8000/docs`
- **Health Check**: `http://localhost:8000/api/chat/health`

## ğŸ“š API Endpoints

### ğŸ”— Core Endpoints

#### `GET /`
Welcome endpoint with API information
```json
{
  "message": "âš¡ Namaste! Welcome to Hitesh AI Chat API",
  "description": "Your tech mentor and chai companion",
  "version": "1.0.0",
  "docs": "/docs",
  "health": "/api/chat/health"
}
```

#### `POST /api/chat/send`
Send a message and get a complete response with processing steps
```json
{
  "content": "Sir mujhe backend development kaise start karna hai?",
  "session_id": "optional-session-id"
}
```

**Response:**
```json
{
  "success": true,
  "message": {
    "id": "uuid",
    "type": "ai",
    "content": "Start with Python + FastAPI ya Node.js + Express...",
    "timestamp": "2024-01-01T00:00:00Z"
  },
  "processing_steps": [
    {
      "step": "analyze",
      "content": "User backend start karna chahta hai...",
      "timestamp": "2024-01-01T00:00:00Z"
    },
    {
      "step": "think",
      "content": "Main bhi jab start kiya tha...",
      "timestamp": "2024-01-01T00:00:00Z"
    },
    {
      "step": "output",
      "content": "Start with Python + FastAPI...",
      "timestamp": "2024-01-01T00:00:00Z"
    }
  ]
}
```

#### `POST /api/chat/stream`
Stream processing steps in real-time using Server-Sent Events
```bash
curl -X POST "http://localhost:8000/api/chat/stream" \
  -H "Content-Type: application/json" \
  -d '{"content": "LangGraph kya hota hai?"}'
```

**Stream Response:**
```
data: {"step": "analyze", "content": "User LangGraph ke baare mein puch raha hai...", "timestamp": "2024-01-01T00:00:00Z", "is_complete": false}

data: {"step": "think", "content": "LangGraph ek powerful tool hai...", "timestamp": "2024-01-01T00:00:00Z", "is_complete": false}

data: {"step": "output", "content": "LangGraph ek way hai nodes ke through flow banane ka...", "timestamp": "2024-01-01T00:00:00Z", "is_complete": true}
```

### ğŸ”§ Utility Endpoints

#### `GET /api/chat/history`
Get chat history for a session
```bash
GET /api/chat/history?session_id=your-session-id
```

#### `DELETE /api/chat/history`
Clear chat history for a session
```bash
DELETE /api/chat/history?session_id=your-session-id
```

#### `GET /api/chat/health`
Health check endpoint
```json
{
  "status": "healthy",
  "timestamp": "2024-01-01T00:00:00Z",
  "version": "1.0.0"
}
```

#### `GET /api/chat/performance`
Get performance statistics
```json
{
  "success": true,
  "performance_stats": {
    "total_requests": 150,
    "avg_response_time": 2.3,
    "cache_hit_rate": 0.75
  }
}
```

#### `POST /api/chat/cache/clear`
Clear all caches
```bash
POST /api/chat/cache/clear
```

#### `GET /api/chat/cache/stats`
Get cache statistics
```json
{
  "success": true,
  "cache_stats": {
    "cache_size": 50,
    "cache_hit_rate": 0.75,
    "avg_response_time": 2.3,
    "total_requests": 150
  }
}
```

## ğŸ§  How It Works

### 1. **Message Processing Flow**
```
User Message â†’ Chat Service â†’ Hitesh AI Service â†’ OpenAI API â†’ Response Processing â†’ Caching â†’ Response
```

### 2. **Step-by-Step Processing**
The AI processes each message through three distinct steps:

1. **ğŸ” Analyze**: Understand and break down the user's query
2. **ğŸ’­ Think**: Reflect on the approach using personal experience and reasoning
3. **ğŸ“¤ Output**: Present the teaching or recommendation

### 3. **Caching Strategy**
- **Response Cache**: Caches AI responses for 1 hour
- **Session Cache**: Maintains conversation context
- **Performance Cache**: Stores frequently accessed data

### 4. **Performance Optimizations**
- **Async Processing**: Non-blocking I/O operations
- **Connection Pooling**: Reuses HTTP connections
- **Token Optimization**: Reduced context window for faster responses
- **Parallel Processing**: Where possible, processes steps concurrently

## ğŸ¨ Hitesh's Personality

The AI simulates Hitesh Choudhary's authentic personality:

### ğŸ—£ï¸ **Speaking Style**
- **Hinglish**: Natural mix of Hindi and English
- **Casual & Relatable**: Like chatting with a friend over chai
- **Encouraging**: Always supportive and motivating
- **Storytelling**: Uses analogies and real-life examples

### ğŸ¯ **Core Topics**
- Backend Development (FastAPI, Express, MongoDB)
- API Development and Authentication
- AI Tools (LangGraph, LangChain, n8n)
- Automation and Workflow Tools
- Career Advice and Tech Education
- YouTube Content Creation
- Productivity and Creator Life

### ğŸ’¬ **Sample Conversations**
```
User: "Sir mujhe backend development kaise start karna hai?"
Hitesh: "Arey bhai, easy hai! Start with Python + FastAPI ya Node.js + Express. 
        Ek 'Hello World API' banao, fir connect karo MongoDB se. 
        Heroku ya Render pe deploy karke confidence le aao. 
        Main bhi pehle sochta tha yeh kya bakchodi haiâ€¦ 
        lekin jab kiya na, toh maza aa gaya! ğŸ˜„"
```

## ğŸš€ Deployment

### Render Deployment
The project is configured for easy deployment on Render:

1. **Connect Repository**: Link your GitHub repository to Render
2. **Environment Variables**: Set `OPENAI_API_KEY` in Render dashboard
3. **Auto Deploy**: Render automatically builds and deploys on push

### Docker Deployment
```bash
# Build image
docker build -t hitesh-ai-api .

# Run container
docker run -d \
  -p 8000:8000 \
  -e OPENAI_API_KEY=your_key \
  -e DEBUG=false \
  --name hitesh-ai-container \
  hitesh-ai-api
```

### Environment Variables
| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_API_KEY` | Your OpenAI API key | Required |
| `DEBUG` | Enable debug mode | `false` |
| `LOG_LEVEL` | Logging level | `info` |

## ğŸ› ï¸ Development

### Running Tests
```bash
python -m pytest test_backend.py
```

### Code Structure
- **Models**: Pydantic models for data validation
- **Routes**: FastAPI route handlers
- **Services**: Business logic and external API integration
- **Utils**: Helper functions and system prompts

### Adding New Features
1. **New Endpoint**: Add to `app/routes/chat.py`
2. **New Model**: Create in `app/models/chat.py`
3. **New Service**: Add to `app/services/` directory
4. **Update Tests**: Modify `test_backend.py`

## ğŸ“Š Performance Metrics

The API includes built-in performance monitoring:

- **Response Time**: Average processing time per request
- **Cache Hit Rate**: Percentage of cached responses
- **Request Count**: Total number of processed requests
- **Error Rate**: Percentage of failed requests

## ğŸ”§ Configuration

### Production Settings
- **Workers**: 1 worker for optimal performance
- **Timeout**: 30 seconds for OpenAI API calls
- **Cache TTL**: 1 hour for response caching
- **Max History**: 10 messages per session

### Development Settings
- **Auto-reload**: Disabled for better performance
- **Debug Mode**: Controlled via environment variable
- **Logging**: Configurable log levels

## ğŸ¤ Contributing

1. **Fork** the repository
2. **Create** a feature branch
3. **Make** your changes
4. **Test** thoroughly
5. **Submit** a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **Hitesh Choudhary**: For inspiring this project with his teaching style
- **OpenAI**: For providing the GPT-4o-mini API
- **FastAPI**: For the excellent web framework
- **Render**: For hosting and deployment services

## ğŸ“ Support

- **Issues**: Create an issue on GitHub
- **Documentation**: Check `/docs` endpoint for interactive API docs
- **Health**: Monitor `/api/chat/health` for system status

---

**Made with â¤ï¸ and lots of â˜• chai**

*"Build karo, break karo, repeat karo!" - Hitesh Choudhary*
